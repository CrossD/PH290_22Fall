---
title: "Parallel Computing on Savio"
subtitle: "PH 290"
author: "Xiongtao Dai"
output:
  xaringan::moon_reader:
    css: [myslides.css, myslides-fonts.css]
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    nature:
      beforeInit: "macros.js"
      highlightLines: false
      countIncrementalSlides: false
---

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
knitr::opts_chunk$set(
  fig.width = 6, fig.height = 6
)
```

## Outline

- Bash tools for working with remote servers

- Savio architecture

- Slurm

- Launching lots of jobs

---

## Resources

- [High Performance Computing documentation at UC Berkeley](https://docs-research-it.berkeley.edu/services/high-performance-computing/overview/)

- [Savio training 10/22/2022](https://www.youtube.com/watch?v=g28Q8oCnA2U)

---

class: big, middle

## Bash tools for working remotely

---

## Working on a remote machine

- Most remote machines uses `bash` as the default shell, so you will issue bash commands

- In your local bash, `ssh destination` will remote login a machine. The destination specification often looks like (this one is for Savio) `username@hpc.brc.berkeley.edu`

- Authentication is needed before you can connect. So if you want to connect to a remote machine, look at its help webpage and see how to set up an account
    - More about setup in HW6

- `scp source:path/on/source destination:path/on/destination` copies a file from a source machine to a destination machine. This lets you copy from any local/remote machine to any other machine. If you prefer a GUI, try WinSCP on Windows or Cyberduck on mac. 
    - [Globus Connect](https://www.globus.org/globus-connect-personal) works great for transferring large files on Savio

---

- When you are working on a remote machine, *your jobs will usually be killed after you log out*

- `tmux` is a window emulator to let you run multiple windows within the same bash session. Your jobs within it will keep running even when you log out or get disconnected
    - It is usually installed on remote machines by default

- `tmux` creates a new session
- Within a session
    - `<C-B>c` creates a new window
    - `<C-B>n` goes to the next window
    - `<C-B>p` goes to the previous window
    - `<C-B>d` detaches the tmux session. You can safely log out bash
- Next time you log in, `tmux attach` reattach to the last session 

---

class: big, middle

## Savio

---

## Savio architecture

![:scale 100%](https://docs-research-it.berkeley.edu/img/SAVIO%20Overview.jpeg)
From [Research IT](https://docs-research-it.berkeley.edu/services/high-performance-computing/overview/system-overview/)

---

- *Login nodes*  are servers available to you for basic jobs like file editing and job submission to compute nodes

- *Compute nodes* are where the heavy computation are carried out. Different nodes may have different hardware

- *Data transfer node* is for transferring large files (say, >1Gb in size)

---

## Slurm workload manager

- `Slurm` is the workload manager used on Savio

- You can specify the number of cores and nodes you would like to request for computing jobs

- Request will contain either specific node numbers or partitions (the latter is more convenient)

- *Partitions* are job queues. Each partition consists of a number of nodes. These nodes are configured differently
    - If a job is sent to a partition, it will be sent to any node(s) within the partition
    - Partition configurations on Savio can be found [here](https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/hardware-config/)
    - Most often we will use `savio2_htc`, `savio2`, `savio3_htc`, or `savio3`

---

## Resource management: Time

- Computation time is accessed via spending *service units (SUs)* 
    - Roughly, 1 core hour = 1 SU. Faster cores are more [expensive](https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/running-your-jobs/service-units-savio/)

- If you went through the setup process in [HW6](../hwlabs/hw6.html), you would have access to the SU account for this course, which is `ic_ph290`

- The HTC cores (`savio2_htc` and `savio3_htc`) are allocated *by core*. So you are charged SUs by core

- Most other cores (e.g., `savio2` and `savio3`) are allocated *by node*. So even if you request 1 core in 1 node, you will be charged for all the cores on the same node

---

## Resource management: Storage

- Your `$HOME` directory has a 10GB quota. It is backed up and is permanent

- Large files (data, intermediate results, etc) can be stored in the `$SCRATCH` directory, where the quota is unlimited. Old files in this directory are purged

- If you need a large permanent storage, your PI needs to purchase it

---

## Getting help for Savio

- Please post any questions about Savio on Ed Discussion or email me, *before* you reach out to Research IT admins

---

class: big, middle

## Slurm

---

## Slurm commands

- `squeue`, view the job queue in Slurm (jobs from everyone). To show your own job, `squeue -u $(whoami)`

- `sinfo` shows information about the partitions
    - `sinfo | idle` filters only the idle ones 
    - `sinfo -o "%.12N %.11T %.14C %.5O %.7e" --Node` shows useful information by node

---

- `salloc` creates a job and allocates resources (for later use). No computation is being run at this moment. Useful flags include
    - `-A account` (required)
    - `-p partition` (required)
    - `-t 1-2:30:00` specifies the job will be killed after 1 day 2 hours and 30 minutes (required)
    - `-N numberOfNodes` (optional)
    - `-n numberOfTasks`. By default, 1 core will be requested per task (optional)
    - `--mem-per-cpu 4G` requests 4G of memory per cpu (optional)

- See `man salloc` for all the flags

- E.g., 
    - `salloc -A ic_ph290 -p savio2_htc -t 1:0:0 -N 1 -n 2` requests 2 cores in 1 node from `savio_htc` partition for at most 1 hour of time. Credit comes from `ic_ph290`

---

- `srun` runs tasks in the Slurm workers
    - `srun --jobid=xxx commandToRun` runs the command once for each task. `--jobid` utilize an existing allocation

- You can run an interactive task using `srun --jobid=xxx --pty bash`

- `scancel jobIDHere` cancels a job

---

## Modules

- `module` command is used to manage software loaded to your session

    - `module load r` loads R (default version is 4.2.1)
    - `module load r-packages` loads common R packages (e.g. `tidyverse`)

- `module list` shows loaded modules

- `module avail` shows all of the available modules

- `module whatis moduleName` and `module show moduleName` display information about the module

---

## Monitoring jobs

- If you are on the login node, `wwall -j jobIDHere` shows some compact info about a job

- To interactively inspect a job, log into an allocated compute node using `ssh nodeNameHere` and then issue `top`

---

class: big, middle

## Running lots of jobs

---

## Batch jobs

You can submit a job using a Slurm batch script. E.g., file `batch`:

```{r,eval=FALSE}
#!/bin/bash

#SBATCH --account=ic_ph290
#SBATCH --time=1:0:0
#SBATCH --partition='savio3_htc'
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=4000M
#SBATCH --job-name=test
#SBATCH --output=testout
#SBATCH --error=testerr

# None-SBATCH commands need to go after the SBATCH commands

export MKL_NUM_THREADS=1 # Use single thread linear algebra

module load r
module load r-packages

Rscript -e 'source("test.R")' # Run R:
```

---

`test.R`:

```{r,eval=FALSE}
library(future.apply)
plan(multicore, workers=availableCores)

a <- matrix(rnorm(9e6), 3e3, 3e3)

print(availableCores())

res <- future_lapply(1:1000, function(i) {
  crossprod(a)
})
```

---

## Running multiple jobs at once

We will introduce a more flexible approach using future shortly, but here are the basic approaches using just Slurm:

- If you want to launch multiple jobs with varying settings (e.g., scenario 0, 1, 2, and 3), you can use [a helper script](https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/running-your-jobs/hthelper-script/)

- Slurm is able to run a job array, where you can run the array task depending on the task number. *But one node will be allocated to each array*

- [Reference](https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/running-your-jobs/submitting-jobs/#Job-submission-with-specific-resource-requirements)

---

## Launching jobs from within R

- We will be using R libraries `future` with `future.batchtools` to request resources and launch jobs from within R

- R will use a batch script template to request resources and will then send parallel jobs to the workers 
    - Here are some [exemplary template files](https://github.com/mllg/batchtools/tree/master/inst/templates)

---

`nested.R`: 
```{r,eval=FALSE}
library(future.apply)
library(future.batchtools)

plan(list(
  tweak(batchtools_slurm,
        workers = 2,
        template = "myslurm.tmpl",
        resources = list(
          account = "ic_ph290",
          walltime = "1:00:00",
          partition="savio3_htc",
          job.name = "nested", log.file = "nested",
          nodes = 1, ntasks = 1, ncpus = 4, mempercpu = 4000,
          blas.threads=1)),
  tweak(multicore, workers=function() 
      future::availableCores(constraints='Slurm'))))


allRes <- future_lapply(c(1e3, 2e3), function(d) {
  a <- matrix(rnorm(d^2), d, d)
  res <- future_lapply(1:1000, function(i) {
    crossprod(a)
  })
  save(res, file=sprintf("%d.RData", d))
}, future.seed=TRUE)
```

---

`myslurm.tmpl`:
```{r,eval=FALSE}
#!/bin/bash

<%
log.file = fs::path_expand(resources$log.file)
-%>

#SBATCH --account=<%= resources$account %>
#SBATCH --partition=<%= resources$partition %>
#SBATCH --time=<%= resources$walltime %>
#SBATCH --job-name=<%= resources$job.name %>
#SBATCH --output=<%= paste0(log.file, "out") %>
#SBATCH --error=<%= paste0(log.file, "err") %>
<%= if (!is.null(resources$nodes)) sprintf("#SBATCH --nodes=%d", resources$nodes) %>
<%= if (!is.null(resources$ntasks)) sprintf("#SBATCH --ntasks=%d", resources$ntasks) %>
<%= if (!is.null(resources$ncpus)) sprintf("#SBATCH --cpus-per-task=%d", resources$ncpus) %>
<%= if (!is.null(resources$mempercpu)) sprintf("#SBATCH --mem-per-cpu=%dM",                  resources$mempercpu) %>

## Initialize work environment
<%= if (!is.null(resources$blas.threads)) sprintf("export MKL_NUM_THREADS=%i",               resources$blas.threads) %>

# module load r-packages

## Run R:
Rscript -e 'batchtools::doJobCollection("<%= uri %>")'
```



